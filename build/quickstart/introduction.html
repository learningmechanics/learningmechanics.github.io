<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Introduction: asking a specific
question - Learning Mechanics</title>
  
  <!-- KaTeX for math rendering -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
  <script defer src="../static/math-render.js"></script>
  
  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
  
  <!-- Our minimal styles -->
  <link rel="stylesheet" href="../static/style.css">
  
  <!-- Meta tags -->
  
  <meta name="author" content="The Learning Mechanics Team">
  <meta name="date" content="2025-09-01">
</head>
<body id="top">
  <a href="../index.html" class="home-glyph"><i class="fas fa-home"></i></a>
  <button class="font-toggle" onclick="cycleFont()"></button>
  <button class="theme-toggle" onclick="toggleTheme()"><i class="fas fa-sun"></i></button>

  <article>
    <header>
                  <div class="sequence-header">
        <h1 class="sequence-name">A Quickstart Guide to Learning
Mechanics</h1>
      </div>
      
            <h1>Introduction: asking a specific question</h1>
            <div class="sequence-nav">
        Part 1 of <a href="../quickstart/introduction.html">A Quickstart
Guide to Learning
Mechanics</a> (<a href="../quickstart/hidden-representations.html">next</a>)
      </div>
            <hr class="title-separator">
      <div class="metadata">
        <a href="https://www.youtube.com/watch?v=dQw4w9WgXcQ">The Learning Mechanics Team</a>
        <br><time datetime="2025-09-01">2025-09-01</time>
      </div>
      <hr class="metadata-separator">
    </header>

    <main>
      <p>The mathematical science of deep learning has had many
      successes over the past decade in the quest to bring principle to
      practical neural networks. It has also had many failures. There is
      now so much literature that it is difficult for newcomers to know
      where to start. This needn‚Äôt be the case: our successes are
      notable but few, experts are converging on useful ideas and
      methodologies, and we should summarize in plain language the
      things that have definitively worked so we can better build on
      them. This guide is a summary of what we see as the ‚Äúessentials of
      deep learning theory‚Äù as of 2026: the parts of the story so far
      that seem to us inevitable, indispensable, and part of the final
      picture we expect to one day put together.</p>
      <p><strong><em>For newcomers:</em></strong> welcome to the science
      of deep learning! It is our belief that neural networks have a
      great deal of mathematical principle behind them. We‚Äôre confident
      that we as a field know some of it, but we haven‚Äôt found most of
      it yet. The field is currently conducting a scientific search for
      these principles, and if you want to contribute, we can use your
      help. Our hope is that this sequence of posts can serve as a
      quickstart guide to the field, summarizing the ideas we‚Äôre quite
      confident will stick around, so you can get up to speed and become
      conversant. We‚Äôll focus on important <em>ideas</em> more than
      important <em>papers,</em> and we‚Äôll tell you what you should get
      out of reading the papers we do share. We will not go into much
      technical detail here, as our intent is just to give you a useful
      map of the essential territory. We‚Äôll highlight open questions ‚Äî
      the big stuff we‚Äôre really curious about that we think is likely
      to unlock future advances ‚Äî as we go. Please feel free to adopt
      them as your own, and tell us what you find.</p>
      <p>Throughout, we‚Äôll assume familiarity with basic deep learning
      and basic math including linear algebra, calculus, and statistics,
      but if you find something unduly confusing (especially if you want
      to fix it yourself), let us know.</p>
      <p><strong><em>For experts in deep learning theory:</em></strong>
      in any scientific enterprise, it‚Äôs useful every once in a while to
      stop, look backwards, and assess our progress. Fields tend to
      sprawl as they advance, and so it is periodically valuable to
      reflect and notice that the important results are rather simpler
      than the path by which we got there. (You will recognize many such
      cases in this guide.) It‚Äôs useful to look backwards and simplify,
      to smooth over the path, to find the simple stories we will one
      day canonize in textbooks. This helps us grizzled veterans as much
      as newcomers, for we‚Äôre all on the same team here, and when we
      agree on our history and goals, we can better work together.</p>
      <p>It‚Äôs the job of all experienced scientists to help teach and
      train the generations below us. It‚Äôs easy to forget with
      experience how hard it is to learn. We‚Äôd like you to share this
      with your younger students and collaborators. It is meant for
      them. If you see ways to make this a better resource, we‚Äôd like to
      hear them.</p>
      <p>Science is an edifice whose bricks are ideas, each supporting
      those laid down above it. While each idea is contributed by one or
      more people, and these contributors deserve credit, here we focus
      more on the ideas. Nonetheless, if you feel we have made any
      attribution errors, do inform us. Furthermore, while this list is
      intended to be minimal, not comprehensive, if we have missed
      anything essential, please tell us.</p>
      <p><strong><em>Relationship to our position paper.</em></strong>
      We‚Äôre releasing this quickstart guide at the same time as our
      position paper, <a
      href="https://www.youtube.com/watch?v=dQw4w9WgXcQ">There Will Be a
      Scientific Theory of Deep Learning</a>. We wrote the paper to be
      punchy, compact, polished, and persuasive: it should get you
      excited to build the fundamental theory of deep learning. In
      contrast, this quickstart guide will help you get started. It is
      written in a style that is more casual, more pedagogical, and
      easier to read and learn from. While the paper is meant to be read
      in one go, this guide is meant to be browsed one chapter at a
      time, mulled over, and returned to. (But of course, if you want to
      read it clean through, don‚Äôt let us discourage you.) While the
      position paper is a static artifact, we may update this guide as
      more of the story of learning mechanics is revealed.</p>
      <h2 id="asking-a-specific-question">Asking a specific
      question</h2>
      <p>Deep learning is complicated. Training a neural network
      involves choosing an architecture, choosing a dataset, selecting
      numerous hyperparameters, and running a long iterated training
      procedure until, eventually, the loss goes down and learning has
      occurred. There will be no simple theory encompassing all of these
      variables ‚Äî there are simply too many. For the time being, it‚Äôs
      important to ask questions simple and specific enough to be
      answered. As we make progress, we can hope to widen each pocket of
      understanding, eventually linking them together into a unified
      picture! As of 2025, though, our progress lies primarily in a few
      disjoint islands that are yet to be linked.</p>
      <p>A good way to go about research in this or any field is to
      narrow in on a specific enough question that it might actually be
      answered. ‚ÄúUnderstanding deep learning‚Äù in the abstract (or
      ‚Äúsolving‚Äù it, and so on) is so big and vague a goal that if you
      reach for it all at once, you‚Äôll come back empty-handed. By the
      same token, a good way to organize this field‚Äôs findings so far is
      in terms of the part of the deep learning process they help you
      understand. We‚Äôll structure our summary of the highlights in this
      way, clustering results according to the type of question they
      help you answer. This clustering is neither definitive nor static:
      these topic questions weren‚Äôt the obvious choices five years ago,
      and they‚Äôll probably be different a few years down the line!
      Nonetheless, the best learning is propelled by genuine curiosity,
      and organizing ideas around questions lets the reader quickly find
      and sink their teeth into the material that seems most
      enticing.</p>
      <p>Without further ado, here‚Äôs this guide‚Äôs table of contents,
      structured as a list of topic questions. We follow this rough
      ordering: the earlier chapters are topics we know more about.
      Earlier topics also turn out to be important for studying later
      topics, and the converse is less true.</p>
    </main>
  </article>

  <hr><div class="sequence-toc"><h3>A Quickstart Guide to Learning Mechanics</h3><ol><li><strong>Introduction: asking a specific question</strong></li><li><a href="../quickstart/hidden-representations.html">The average size of hidden representations</a></li><li><a href="../quickstart/hyperparameter-selection.html">Hyperparameter selection (and why theorists should care)</a></li><li><a href="../quickstart/optimization.html">The dynamics of optimization</a></li><li><a href="../quickstart/feature-learning.html">üöß Feature learning and the final network weights</a></li><li><a href="../quickstart/generalization.html">üöß Generalization</a></li><li><a href="../quickstart/sparsity.html">üöß Neuron-level sparsity</a></li><li><a href="../quickstart/data-structure.html">üöß The structure in the data</a></li><li><a href="../quickstart/conclusion.html">üöß Places to make a difference</a></li></ol></div><div class="back-to-top"><a href="#top"><i class="fas fa-arrow-circle-up"></i></a></div>

  <div class="comments">
    <h2>Comments</h2>
    <script>
      (function() {
        var theme = localStorage.getItem('theme') || 'light';
        var s = document.createElement('script');
        s.src = 'https://giscus.app/client.js';
        s.setAttribute('data-repo', 'learningmechanics/learningmechanics.github.io');
        s.setAttribute('data-repo-id', 'R_kgDOO_nSsA');
        s.setAttribute('data-category', 'Blog Comments');
        s.setAttribute('data-category-id', 'DIC_kwDOO_nSsM4Cualh');
        s.setAttribute('data-mapping', 'pathname');
        s.setAttribute('data-strict', '0');
        s.setAttribute('data-reactions-enabled', '1');
        s.setAttribute('data-emit-metadata', '0');
        s.setAttribute('data-input-position', 'bottom');
        s.setAttribute('data-theme', theme);
        s.setAttribute('data-lang', 'en');
        s.setAttribute('crossorigin', 'anonymous');
        s.async = true;
        document.currentScript.parentNode.appendChild(s);
      })();
    </script>
  </div>


  <script>
    // Font switcher
    const fonts = [
      { name: 'ET Book', family: "'et-book', 'ETBookOT', 'ET Book', Georgia, 'Times New Roman', serif" },
      { name: 'Gill Sans', family: "'Gill Sans', 'Gill Sans MT', Calibri, sans-serif" },
      { name: 'Georgia', family: "Georgia, 'Times New Roman', serif" },
      { name: 'Palatino', family: "Palatino, 'Palatino Linotype', 'Book Antiqua', serif" },
      { name: 'Garamond', family: "Garamond, 'Apple Garamond', 'Baskerville', serif" },
      { name: 'Baskerville', family: "Baskerville, 'Baskerville Old Face', 'Hoefler Text', Garamond, serif" },
      { name: 'Times', family: "'Times New Roman', Times, serif" },
      { name: 'Helvetica', family: "Helvetica, Arial, sans-serif" },
      { name: 'Comic Sans', family: "'Comic Sans MS', 'Comic Sans', cursive" },
      { name: 'Wingdings', family: "Wingdings, 'Zapf Dingbats', serif" }
    ];

    function updateFontButton(fontName) {
      const button = document.querySelector('.font-toggle');
      button.textContent = `üî§ font:  (click to change)`;
    }

    function cycleFont() {
      const currentFont = localStorage.getItem('font') || 'ET Book';
      const currentIndex = fonts.findIndex(f => f.name === currentFont);
      const nextIndex = (currentIndex + 1) % fonts.length;
      const nextFont = fonts[nextIndex];

      document.body.style.fontFamily = nextFont.family;
      localStorage.setItem('font', nextFont.name);
      updateFontButton(nextFont.name);
    }

    function toggleTheme() {
      const currentTheme = document.documentElement.getAttribute('data-theme');
      const newTheme = currentTheme === 'dark' ? 'light' : 'dark';

      document.documentElement.setAttribute('data-theme', newTheme);
      localStorage.setItem('theme', newTheme);

      // Update button icon
      const icon = document.querySelector('.theme-toggle i');
      icon.className = newTheme === 'dark' ? 'fas fa-sun' : 'fas fa-moon';

      // Update Giscus theme
      const giscusFrame = document.querySelector('iframe.giscus-frame');
      if (giscusFrame) {
        giscusFrame.contentWindow.postMessage({
          giscus: { setConfig: { theme: newTheme } }
        }, 'https://giscus.app');
      }
    }

    // Initialize theme and font on page load
    document.addEventListener('DOMContentLoaded', function() {
      // Theme
      const savedTheme = localStorage.getItem('theme') || 'light';
      document.documentElement.setAttribute('data-theme', savedTheme);

      const icon = document.querySelector('.theme-toggle i');
      icon.className = savedTheme === 'dark' ? 'fas fa-sun' : 'fas fa-moon';

      // Font
      const savedFont = localStorage.getItem('font') || 'ET Book';
      const font = fonts.find(f => f.name === savedFont) || fonts[0];
      document.body.style.fontFamily = font.family;
      updateFontButton(font.name);
    });
  </script>
</body>
</html> 